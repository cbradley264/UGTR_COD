{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNBv+x/8tf4GnniOtjNB7ZK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbradley264/UGTR_COD/blob/main/COD_570.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this code is to reimplement a paper titled \"Uncertainty- Guided Transformer Reasoning for Camoflauged Object Detection\".\n",
        "Note: In order to make this work, you must add the TestDataset to your Google Drive, and from there you must include the path to the CHAMELEON dataset for both dataset_path and gt_path."
      ],
      "metadata": {
        "id": "dQHU-GFKDlgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "0RwvOMe_diFc"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcCw06fpDfdy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Can I can use GPU now? -- {torch.cuda.is_available()}')"
      ],
      "metadata": {
        "id": "Bbs-cvGB0dXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RYHNfM7zh5gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/My Drive/ECE570/TestDataset/CHAMELEON'\n",
        "gt_path = '/content/drive/My Drive/ECE570/TestDataset/CHAMELEON/GT'\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomResizedCrop((128, 128), scale=(0.75, 1.25)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "nl8xo0tIgtdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_position_encoding(dim, height, width):\n",
        "    y_embed = torch.linspace(0, 1, steps=height).unsqueeze(1).repeat(1, width)\n",
        "    x_embed = torch.linspace(0, 1, steps=width).unsqueeze(0).repeat(height, 1)\n",
        "    y_embed = y_embed.unsqueeze(0).expand(dim // 2, -1, -1)\n",
        "    x_embed = x_embed.unsqueeze(0).expand(dim // 2, -1, -1)\n",
        "    pos_encoding = torch.cat([x_embed, y_embed], dim=0).unsqueeze(0)\n",
        "    return pos_encoding"
      ],
      "metadata": {
        "id": "RZYpwaHWzQ_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UGTR(nn.Module):\n",
        "    def __init__(self, classes=1, zoom_factor=8, pretrained=True):\n",
        "        super(UGTR, self).__init__()\n",
        "        self.zoom_factor = zoom_factor\n",
        "        self.classes = classes\n",
        "\n",
        "        resnet = models.resnet50(pretrained=pretrained)\n",
        "        self.layer0 = nn.Sequential(\n",
        "            resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool\n",
        "        )\n",
        "        self.layer1, self.layer2, self.layer3, self.layer4 = (\n",
        "            resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4\n",
        "        )\n",
        "\n",
        "        self.hidden_dim = 256\n",
        "        self.input_proj = nn.Conv2d(2048, self.hidden_dim, kernel_size=1)\n",
        "        self.channel_adjust = nn.Conv2d(1, 256, kernel_size=1)\n",
        "\n",
        "        encoder_layer = TransformerEncoderLayer(\n",
        "            d_model=self.hidden_dim, nhead=8, dim_feedforward=512, dropout=0.1\n",
        "        )\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=3)\n",
        "\n",
        "        self.pred = nn.Conv2d(self.hidden_dim, classes, kernel_size=1)\n",
        "        self.mean_conv = nn.Conv2d(self.hidden_dim, 1, kernel_size=1)\n",
        "        self.logvar_conv = nn.Conv2d(self.hidden_dim, 1, kernel_size=1)\n",
        "\n",
        "    def reparameterize(self, mu, logvar, k=1):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        sample_z = eps.mul(std).add_(mu)\n",
        "        return sample_z\n",
        "\n",
        "    def reduce_channels(self, x):\n",
        "        if not hasattr(self, 'reduce_conv'):\n",
        "            self.reduce_conv = nn.Conv2d(x.shape[1], self.hidden_dim, kernel_size=1).to(x.device)\n",
        "        return self.reduce_conv(x) # Use the existing layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()\n",
        "        h = int((x_size[2] - 1) / 8 * self.zoom_factor + 1)\n",
        "        w = int((x_size[3] - 1) / 8 * self.zoom_factor + 1)\n",
        "\n",
        "        x = self.layer0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        # x = self.reduce_channels(x)\n",
        "        x = self.input_proj(x)\n",
        "\n",
        "        pos_encoding = build_position_encoding(self.hidden_dim, x.shape[2], x.shape[3]).to(x.device)\n",
        "        x = x + pos_encoding\n",
        "\n",
        "        batch_size, c, height, width = x.shape\n",
        "        x = x.flatten(2).permute(2, 0, 1)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x.permute(1, 2, 0).view(batch_size, c, height, width)\n",
        "\n",
        "        mean = self.mean_conv(x)\n",
        "        logvar = self.logvar_conv(x)\n",
        "\n",
        "        prob_x = self.reparameterize(mean, logvar, k=1)\n",
        "        uncertainty = torch.exp(logvar)\n",
        "\n",
        "        prob_x = self.channel_adjust(prob_x)\n",
        "        pred = torch.sigmoid(self.pred(prob_x))\n",
        "\n",
        "        if self.zoom_factor != 1:\n",
        "            pred = F.interpolate(pred, size=(h, w), mode='bilinear', align_corners=True)\n",
        "            uncertainty = F.interpolate(uncertainty, size=(h, w), mode='bilinear', align_corners=True)\n",
        "\n",
        "        return pred, uncertainty\n"
      ],
      "metadata": {
        "id": "yWnXtW2ad_e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def poly_lr_scheduler(optimizer, base_lr, iter, max_iter, power):\n",
        "  lr = base_lr * (1 - iter / max_iter) ** power\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = lr"
      ],
      "metadata": {
        "id": "F_L55vqjERk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, criterion, optimizer, device, num_epochs=10, checkpoint_path='model_checkpoint.pth', base_lr=1e-4, power=0.9):\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "\n",
        "    max_iter = len(dataloader) * num_epochs\n",
        "    global_iter = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0.0\n",
        "        epoch_uncertainty_loss = 0.0\n",
        "        num_batches = len(dataloader)\n",
        "\n",
        "        with tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
        "            for images, targets in pbar:\n",
        "                images, targets = images.to(device), targets.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs, uncertainty = model(images)\n",
        "                targets = targets.view(-1, 1, 1, 1).repeat(1, 1, outputs.shape[2], outputs.shape[3]).float()\n",
        "                main_loss = criterion(outputs, targets)\n",
        "                uncertainty_loss = torch.mean(uncertainty)\n",
        "                loss = main_loss + 0.1 * uncertainty_loss\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                poly_lr_scheduler(optimizer, base_lr, global_iter, max_iter, power)\n",
        "                epoch_loss += main_loss.item()\n",
        "                epoch_uncertainty_loss += uncertainty_loss.item()\n",
        "                pbar.set_postfix({\n",
        "                    'Loss': epoch_loss / (pbar.n + 1),\n",
        "                    'Uncertainty Loss': epoch_uncertainty_loss / (pbar.n + 1)\n",
        "                })\n",
        "\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss / num_batches:.4f}, Uncertainty Loss: {epoch_uncertainty_loss / num_batches:.4f}\")\n",
        "\n",
        "    print(\"Training completed.\")"
      ],
      "metadata": {
        "id": "Wyf_aCLTepvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    total_loss = 0.0\n",
        "    uncertainty_loss = 0.0\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        with tqdm(dataloader, desc=\"Testing\", unit=\"batch\") as pbar:\n",
        "            for images, targets in pbar:\n",
        "                images, targets = images.to(device), targets.to(device)\n",
        "\n",
        "                outputs, uncertainty = model(images)\n",
        "                targets = targets.view(-1, 1, 1, 1).repeat(1, 1, outputs.shape[2], outputs.shape[3]).float()\n",
        "                main_loss = criterion(outputs, targets)\n",
        "                uncertainty_loss_batch = torch.mean(uncertainty)\n",
        "                loss = main_loss + 0.1 * uncertainty_loss_batch\n",
        "\n",
        "                total_loss += main_loss.item()\n",
        "                uncertainty_loss += uncertainty_loss_batch.item()\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    'Loss': total_loss / (pbar.n + 1),\n",
        "                    'Uncertainty Loss': uncertainty_loss / (pbar.n + 1)\n",
        "                })\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_uncertainty_loss = uncertainty_loss / num_batches\n",
        "    print(f\"Test Loss: {avg_loss:.4f}, Uncertainty Loss: {avg_uncertainty_loss:.4f}\")\n",
        "    return avg_loss, avg_uncertainty_loss"
      ],
      "metadata": {
        "id": "K5pSr0jeeuYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, device, ground_truth_folder, dataset):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    mae_scores = []\n",
        "    e_scores = []\n",
        "    s_scores = []\n",
        "    f_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "      with tqdm(dataloader, desc=\"Evaluating\", unit=\"batch\") as pbar:\n",
        "        for images, targets in pbar:\n",
        "          images = images.to(device)\n",
        "\n",
        "          predictions, _ = model(images)\n",
        "          predictions = predictions.squeeze(1)\n",
        "\n",
        "          predicted_masks = (predictions > 0.5).float()\n",
        "\n",
        "          # for idx in range(len(targets)):\n",
        "          for idx, animal_num in enumerate(targets):\n",
        "            gt_path = f\"{ground_truth_folder}/animal-{76-animal_num}.png\"\n",
        "            # image_path = dataset.imgs[targets[idx]][0]\n",
        "            # image_name = os.path.basename(image_path)\n",
        "            # gt_name = os.path.splitext(image_name)[0] + \".png\"\n",
        "            # gt_path = os.path.join(ground_truth_folder, gt_name)\n",
        "            ground_truth = load_ground_truth(gt_path).to(device)\n",
        "            ground_truth = transforms.Resize(predicted_masks[idx].shape[-2:])(ground_truth)\n",
        "\n",
        "            mae = torch.mean(torch.abs(predicted_masks[idx] - ground_truth)).item()\n",
        "            mae_scores.append(mae)\n",
        "\n",
        "            e_measure = calculate_e_measure(predicted_masks[idx], ground_truth)\n",
        "            e_scores.append(e_measure)\n",
        "\n",
        "            s_measure = calculate_s_measure(predicted_masks[idx], ground_truth)\n",
        "            s_scores.append(s_measure)\n",
        "\n",
        "            f_measure = calculate_f_measure(predicted_masks[idx], ground_truth)\n",
        "            f_scores.append(f_measure)\n",
        "\n",
        "    mean_mae = np.mean(mae_scores)\n",
        "    mean_e = np.mean(e_scores)\n",
        "    mean_s = np.mean(s_scores)\n",
        "    mean_f = np.mean(f_scores)\n",
        "\n",
        "    print(f\"Mean MAE: {mean_mae:.4f}\")\n",
        "    print(f\"Mean E-measure (Eφ): {mean_e:.4f}\")\n",
        "    print(f\"Mean S-measure (Sα): {mean_s:.4f}\")\n",
        "    print(f\"Mean Weighted F-measure (Fwβ): {mean_f:.4f}\")\n",
        "\n",
        "def load_ground_truth(filepath):\n",
        "    \"\"\"Load ground truth as a tensor from a given path.\"\"\"\n",
        "    from PIL import Image\n",
        "    import torchvision.transforms as transforms\n",
        "\n",
        "    image = Image.open(filepath).convert(\"L\")\n",
        "    transform = transforms.ToTensor()\n",
        "    tensor_image = transform(image)\n",
        "    tensor_image = (tensor_image > 0.5).float()\n",
        "    return tensor_image\n",
        "\n",
        "def calculate_e_measure(pred, gt):\n",
        "    \"\"\"Calculate the mean E-measure (Eφ).\"\"\"\n",
        "    pred = pred.cpu().numpy()\n",
        "    gt = gt.cpu().numpy()\n",
        "    gt_mean = np.mean(gt)\n",
        "    precision_map = (pred * gt_mean + gt * np.mean(pred)) / (gt_mean + np.mean(pred) + 1e-8)\n",
        "    e_measure = np.mean(precision_map)\n",
        "    return e_measure\n",
        "\n",
        "def calculate_s_measure(pred, gt):\n",
        "    \"\"\"Calculate the mean S-measure (Sα).\"\"\"\n",
        "    pred = pred.cpu().numpy()\n",
        "    gt = gt.cpu().numpy()\n",
        "    alpha = 0.5\n",
        "    obj_score = 2 * np.sum(pred * gt) / (np.sum(pred) + np.sum(gt) + 1e-8)\n",
        "\n",
        "    pred_fg = pred * (gt >= 0.5)\n",
        "    gt_fg = gt * (gt >= 0.5)\n",
        "    pred_bg = pred * (gt < 0.5)\n",
        "    gt_bg = gt * (gt < 0.5)\n",
        "\n",
        "    region_fg = 2 * np.sum(pred_fg * gt_fg) / (np.sum(pred_fg) + np.sum(gt_fg) + 1e-8)\n",
        "    region_bg = 2 * np.sum(pred_bg * gt_bg) / (np.sum(pred_bg) + np.sum(gt_bg) + 1e-8)\n",
        "\n",
        "    s_measure = alpha * obj_score + (1 - alpha) * 0.5 * (region_fg + region_bg)\n",
        "    return s_measure\n",
        "\n",
        "def calculate_f_measure(pred, gt, beta_square=0.3):\n",
        "    \"\"\"Calculate the Weighted F-measure (Fwβ).\"\"\"\n",
        "    pred = pred.cpu().numpy().flatten()\n",
        "    gt = gt.cpu().numpy().flatten()\n",
        "    gt = (gt > 0.5).astype(int)\n",
        "    precision = precision_score(gt, pred, zero_division=0)\n",
        "    recall = recall_score(gt, pred, zero_division=0)\n",
        "\n",
        "    if precision + recall == 0:\n",
        "        return 0.0\n",
        "\n",
        "    f_measure = (1 + beta_square) * (precision * recall) / (beta_square * precision + recall + 1e-8)\n",
        "    return f_measure"
      ],
      "metadata": {
        "id": "TMzzQcqK4KDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UGTR()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# train(model, train_loader, criterion, optimizer, device, num_epochs=20, checkpoint_path='model_checkpoint.pth', base_lr=1e-4, power=0.9)\n",
        "# test_loss, test_uncertainty_loss = test(model, test_loader, criterion, device)\n",
        "\n",
        "evaluate_model(model, test_loader, device, gt_path, test_dataset)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PX8L2hCNe5_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}